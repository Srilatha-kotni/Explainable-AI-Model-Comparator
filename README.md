In real-world machine learning systems, choosing a model based only on accuracy can be risky.
Models with similar accuracy may behave very differently in terms of bias, reliability, and interpretability, which can lead to poor or unethical decisions.

Most ML projects train a single model and stop there.
This project focuses on trust-aware model evaluation.

This project provides an Explainable AI platform where users can:
ðŸš€ Features

ðŸ“‚ Upload any CSV dataset
ðŸŽ¯ Choose priority: Accuracy, Fairness, or Stability
ðŸ“Š Visual comparison using animated progress bars
ðŸ¤– Explainable model recommendation

FastAPI backend
React + Tailwind frontend
REST APIs with live interaction
