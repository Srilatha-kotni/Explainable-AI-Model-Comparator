In real-world machine learning systems, choosing a model based only on accuracy can be risky.
Models with similar accuracy may behave very differently in terms of bias, reliability, and interpretability, which can lead to poor or unethical decisions.

Most ML projects train a single model and stop there.
This project focuses on trust-aware model evaluation.

This project provides an Explainable AI platform where users can:
  Upload their own dataset (CSV)
  Automatically train multiple ML models
  Compare models using transparent evaluation metrics
  Receive a model recommendation based on their priorities

üåê Full-Stack Implementation

FastAPI backend
React + Tailwind frontend
REST APIs with live interaction
